{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the first HIV related websites file (positive class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "pos_class_list1 = []\n",
    "with open(\"pos_class.jsonl\") as json_file:\n",
    "   for line in json_file:\n",
    "    pos_class_list1.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>text_dump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.hivsharespace.net</td>\n",
       "      <td>Skip to main content En Fr Pt HOME | ABOUT | C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.dapp-namibia.org</td>\n",
       "      <td>Register \\r\\n                                 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.pepfar.gov</td>\n",
       "      <td>Skip to Main Content PEPFAR Seal The United St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.arasa.info</td>\n",
       "      <td>Home AIDS 2016 About Staff Office Addresses Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://hivsa.com</td>\n",
       "      <td>facebook twitter linkedin youtube Home Who We ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         domain  \\\n",
       "0  http://www.hivsharespace.net   \n",
       "1   http://www.dapp-namibia.org   \n",
       "2        https://www.pepfar.gov   \n",
       "3         http://www.arasa.info   \n",
       "4              http://hivsa.com   \n",
       "\n",
       "                                           text_dump  \n",
       "0  Skip to main content En Fr Pt HOME | ABOUT | C...  \n",
       "1  Register \\r\\n                                 ...  \n",
       "2  Skip to Main Content PEPFAR Seal The United St...  \n",
       "3  Home AIDS 2016 About Staff Office Addresses Co...  \n",
       "4  facebook twitter linkedin youtube Home Who We ...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dataframe from the pos_class_list1: pos_sites1\n",
    "pos_sites1= pd.DataFrame(pos_class_list1)\n",
    "pos_sites1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>text_dump</th>\n",
       "      <th>HIV_related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.hivsharespace.net</td>\n",
       "      <td>Skip to main content En Fr Pt HOME | ABOUT | C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.dapp-namibia.org</td>\n",
       "      <td>Register \\r\\n                                 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.pepfar.gov</td>\n",
       "      <td>Skip to Main Content PEPFAR Seal The United St...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.arasa.info</td>\n",
       "      <td>Home AIDS 2016 About Staff Office Addresses Co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://hivsa.com</td>\n",
       "      <td>facebook twitter linkedin youtube Home Who We ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         domain  \\\n",
       "0  http://www.hivsharespace.net   \n",
       "1   http://www.dapp-namibia.org   \n",
       "2        https://www.pepfar.gov   \n",
       "3         http://www.arasa.info   \n",
       "4              http://hivsa.com   \n",
       "\n",
       "                                           text_dump  HIV_related  \n",
       "0  Skip to main content En Fr Pt HOME | ABOUT | C...            1  \n",
       "1  Register \\r\\n                                 ...            1  \n",
       "2  Skip to Main Content PEPFAR Seal The United St...            1  \n",
       "3  Home AIDS 2016 About Staff Office Addresses Co...            1  \n",
       "4  facebook twitter linkedin youtube Home Who We ...            1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a label column of 1s indicating that the sites are HIV related sites\n",
    "pos_sites1[\"HIV_related\"]=1\n",
    "pos_sites1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the first NOT HIV related sites folder (Negative Class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>text_dump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://stackoverflow.com</td>\n",
       "      <td>Stack Overflow Questions Developer Jobs Tags U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://en.wikipedia.org</td>\n",
       "      <td>Cat From Wikipedia, the free encyclopedia \\n\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.farming-simulator.com</td>\n",
       "      <td>Updates Support Australia (en) Belgien (de) Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.canva.com</td>\n",
       "      <td>+1 335  Tweet 714  Share 8.5K  Pin 28.4K  Sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://hello.com</td>\n",
       "      <td>about us inspiration graphic novel best of hel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              domain  \\\n",
       "0          https://stackoverflow.com   \n",
       "1           https://en.wikipedia.org   \n",
       "2  https://www.farming-simulator.com   \n",
       "3              https://www.canva.com   \n",
       "4                  https://hello.com   \n",
       "\n",
       "                                           text_dump  \n",
       "0  Stack Overflow Questions Developer Jobs Tags U...  \n",
       "1  Cat From Wikipedia, the free encyclopedia \\n\\t...  \n",
       "2  Updates Support Australia (en) Belgien (de) Be...  \n",
       "3   +1 335  Tweet 714  Share 8.5K  Pin 28.4K  Sha...  \n",
       "4  about us inspiration graphic novel best of hel...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_sites1=pd.read_json(\"neg_class.jsonl\", lines=True)\n",
    "neg_sites1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>text_dump</th>\n",
       "      <th>HIV_related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://stackoverflow.com</td>\n",
       "      <td>Stack Overflow Questions Developer Jobs Tags U...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://en.wikipedia.org</td>\n",
       "      <td>Cat From Wikipedia, the free encyclopedia \\n\\t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.farming-simulator.com</td>\n",
       "      <td>Updates Support Australia (en) Belgien (de) Be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.canva.com</td>\n",
       "      <td>+1 335  Tweet 714  Share 8.5K  Pin 28.4K  Sha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://hello.com</td>\n",
       "      <td>about us inspiration graphic novel best of hel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              domain  \\\n",
       "0          https://stackoverflow.com   \n",
       "1           https://en.wikipedia.org   \n",
       "2  https://www.farming-simulator.com   \n",
       "3              https://www.canva.com   \n",
       "4                  https://hello.com   \n",
       "\n",
       "                                           text_dump  HIV_related  \n",
       "0  Stack Overflow Questions Developer Jobs Tags U...            0  \n",
       "1  Cat From Wikipedia, the free encyclopedia \\n\\t...            0  \n",
       "2  Updates Support Australia (en) Belgien (de) Be...            0  \n",
       "3   +1 335  Tweet 714  Share 8.5K  Pin 28.4K  Sha...            0  \n",
       "4  about us inspiration graphic novel best of hel...            0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a label column of 0s indicating the sites are NOT HIV related sites\n",
    "neg_sites1[\"HIV_related\"]=0\n",
    "neg_sites1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the second HIV related sites folder (Positive Class 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON: json_data\n",
    "import json\n",
    "\n",
    "pos_class_list2 = []\n",
    "with open(\"pos_class1.jsonl\") as json_file:\n",
    "   for line in json_file:\n",
    "    pos_class_list2.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>text_dump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.pepfar.gov</td>\n",
       "      <td>Skip to Main Content PEPFAR Seal The United St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.viivhealthcare.com</td>\n",
       "      <td>JavaScript is disabled.Please enable to contin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://hivsa.com</td>\n",
       "      <td>facebook twitter linkedin youtube Home Who We ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.ghfp.net</td>\n",
       "      <td>Jump to navigation Toggle navigation  SIGN IN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.dapp-namibia.org</td>\n",
       "      <td>Register \\r\\n                                 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           domain  \\\n",
       "0          https://www.pepfar.gov   \n",
       "1  https://www.viivhealthcare.com   \n",
       "2                http://hivsa.com   \n",
       "3            https://www.ghfp.net   \n",
       "4     http://www.dapp-namibia.org   \n",
       "\n",
       "                                           text_dump  \n",
       "0  Skip to Main Content PEPFAR Seal The United St...  \n",
       "1  JavaScript is disabled.Please enable to contin...  \n",
       "2  facebook twitter linkedin youtube Home Who We ...  \n",
       "3  Jump to navigation Toggle navigation  SIGN IN ...  \n",
       "4  Register \\r\\n                                 ...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_sites2=pd.DataFrame(pos_class_list2)\n",
    "pos_sites2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>text_dump</th>\n",
       "      <th>HIV_related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.pepfar.gov</td>\n",
       "      <td>Skip to Main Content PEPFAR Seal The United St...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.viivhealthcare.com</td>\n",
       "      <td>JavaScript is disabled.Please enable to contin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://hivsa.com</td>\n",
       "      <td>facebook twitter linkedin youtube Home Who We ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.ghfp.net</td>\n",
       "      <td>Jump to navigation Toggle navigation  SIGN IN ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.dapp-namibia.org</td>\n",
       "      <td>Register \\r\\n                                 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           domain  \\\n",
       "0          https://www.pepfar.gov   \n",
       "1  https://www.viivhealthcare.com   \n",
       "2                http://hivsa.com   \n",
       "3            https://www.ghfp.net   \n",
       "4     http://www.dapp-namibia.org   \n",
       "\n",
       "                                           text_dump  HIV_related  \n",
       "0  Skip to Main Content PEPFAR Seal The United St...            1  \n",
       "1  JavaScript is disabled.Please enable to contin...            1  \n",
       "2  facebook twitter linkedin youtube Home Who We ...            1  \n",
       "3  Jump to navigation Toggle navigation  SIGN IN ...            1  \n",
       "4  Register \\r\\n                                 ...            1  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a label column of 1s indicating the sites are HIV related sites\n",
    "pos_sites2[\"HIV_related\"]=1\n",
    "pos_sites2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the second NOT HIV related sites folder (Negative Class2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON: json_data\n",
    "import json\n",
    "\n",
    "neg_class_list2 = []\n",
    "with open(\"neg_class1.jsonl\") as json_file:\n",
    "   for line in json_file:\n",
    "    neg_class_list2.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>text_dump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://hello.com</td>\n",
       "      <td>about us inspiration graphic novel best of hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.farming-simulator.com</td>\n",
       "      <td>Updates Support Australia (en) Belgien (de) Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.random.org</td>\n",
       "      <td>Home Games Lottery Quick Pick Keno Quick Pick ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://storify.com</td>\n",
       "      <td>Browse Log In Storify Update We appreciate tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://stackoverflow.com</td>\n",
       "      <td>Stack Overflow Questions Developer Jobs Tags U...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              domain  \\\n",
       "0                  https://hello.com   \n",
       "1  https://www.farming-simulator.com   \n",
       "2             https://www.random.org   \n",
       "3                https://storify.com   \n",
       "4          https://stackoverflow.com   \n",
       "\n",
       "                                           text_dump  \n",
       "0  about us inspiration graphic novel best of hel...  \n",
       "1  Updates Support Australia (en) Belgien (de) Be...  \n",
       "2  Home Games Lottery Quick Pick Keno Quick Pick ...  \n",
       "3  Browse Log In Storify Update We appreciate tho...  \n",
       "4  Stack Overflow Questions Developer Jobs Tags U...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_sites2=pd.DataFrame(neg_class_list2)\n",
    "neg_sites2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>text_dump</th>\n",
       "      <th>HIV_related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://hello.com</td>\n",
       "      <td>about us inspiration graphic novel best of hel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.farming-simulator.com</td>\n",
       "      <td>Updates Support Australia (en) Belgien (de) Be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.random.org</td>\n",
       "      <td>Home Games Lottery Quick Pick Keno Quick Pick ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://storify.com</td>\n",
       "      <td>Browse Log In Storify Update We appreciate tho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://stackoverflow.com</td>\n",
       "      <td>Stack Overflow Questions Developer Jobs Tags U...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              domain  \\\n",
       "0                  https://hello.com   \n",
       "1  https://www.farming-simulator.com   \n",
       "2             https://www.random.org   \n",
       "3                https://storify.com   \n",
       "4          https://stackoverflow.com   \n",
       "\n",
       "                                           text_dump  HIV_related  \n",
       "0  about us inspiration graphic novel best of hel...            0  \n",
       "1  Updates Support Australia (en) Belgien (de) Be...            0  \n",
       "2  Home Games Lottery Quick Pick Keno Quick Pick ...            0  \n",
       "3  Browse Log In Storify Update We appreciate tho...            0  \n",
       "4  Stack Overflow Questions Developer Jobs Tags U...            0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a label column of 0s indicating the sites are NOT HIV related sites\n",
    "neg_sites2[\"HIV_related\"]=0\n",
    "neg_sites2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all the dataframes which were loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 67 entries, 0 to 66\n",
      "Data columns (total 3 columns):\n",
      "domain         67 non-null object\n",
      "text_dump      67 non-null object\n",
      "HIV_related    67 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Merge the negative and the positive class dataframes by append() method\n",
    "sites= pos_sites1.append(neg_sites1).append(pos_sites2).append(neg_sites2)\n",
    "\n",
    "# Reset the index \n",
    "sites.reset_index(drop=True, inplace=True)\n",
    "sites.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>text_dump</th>\n",
       "      <th>HIV_related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.hivsharespace.net</td>\n",
       "      <td>Skip to main content En Fr Pt HOME | ABOUT | C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.dapp-namibia.org</td>\n",
       "      <td>Register \\r\\n                                 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.pepfar.gov</td>\n",
       "      <td>Skip to Main Content PEPFAR Seal The United St...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.arasa.info</td>\n",
       "      <td>Home AIDS 2016 About Staff Office Addresses Co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://hivsa.com</td>\n",
       "      <td>facebook twitter linkedin youtube Home Who We ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         domain  \\\n",
       "0  http://www.hivsharespace.net   \n",
       "1   http://www.dapp-namibia.org   \n",
       "2        https://www.pepfar.gov   \n",
       "3         http://www.arasa.info   \n",
       "4              http://hivsa.com   \n",
       "\n",
       "                                           text_dump  HIV_related  \n",
       "0  Skip to main content En Fr Pt HOME | ABOUT | C...            1  \n",
       "1  Register \\r\\n                                 ...            1  \n",
       "2  Skip to Main Content PEPFAR Seal The United St...            1  \n",
       "3  Home AIDS 2016 About Staff Office Addresses Co...            1  \n",
       "4  facebook twitter linkedin youtube Home Who We ...            1  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the Text Data\n",
    "\n",
    "- Remove **non-alphabetic** characters,\n",
    "- **Remove stop words** \n",
    "- **Lemmatize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a Series to store the labels: y\n",
    "y = sites.HIV_related\n",
    "#print(y.head(), \"\\n\")\n",
    "\n",
    "# Create X (features dataset)\n",
    "X= sites.text_dump\n",
    "#print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test sets\n",
    "# Use a test_size of 0.33 and a random_state of 5\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute 5-fold cross-validation scores: cv_scores\n",
    "cv_scores = cross_val_score(reg, X, y, cv=5)\n",
    "\n",
    "# Print the 5-fold cross-validation scores\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the token pattern in order to include only alphabethical characters: TOKENS_ALPHA_ONLY \n",
    "TOKENS_ALPHA_ONLY = '[A-Za-z]+(?=\\\\s+)'\n",
    "\n",
    "# Initialize a CountVectorizer object: count_vectorizer\n",
    "# Specify the argument stop_words=\"english\" so that stop words are removed\n",
    "# token_pattern=TOKENS_ALPHA_ONLY\n",
    "count_vectorizer = CountVectorizer(stop_words='english', token_pattern=TOKENS_ALPHA_ONLY, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>great</th>\n",
       "      <th>great today</th>\n",
       "      <th>like</th>\n",
       "      <th>t</th>\n",
       "      <th>t like</th>\n",
       "      <th>today</th>\n",
       "      <th>today t</th>\n",
       "      <th>wheather</th>\n",
       "      <th>wheather great</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   great  great today  like  t  t like  today  today t  wheather  \\\n",
       "0      1            1     1  1       1      1        1         1   \n",
       "\n",
       "   wheather great  \n",
       "0               1  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the outcome of count_vectorizer on a simple data\n",
    "sample= count_vectorizer.fit_transform([\"Wheather is GReat today but i don't like part-2\"])\n",
    "sample_df= pd.DataFrame(sample.toarray(), columns=count_vectorizer.get_feature_names())\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<44x32160 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 43103 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and transform the training data using only X_train ('text_dump' column values): train_dtm\n",
    "# Create train document term matrix by using the .fit_transform() method\n",
    "train_dtm = count_vectorizer.fit_transform(X_train)\n",
    "train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert sparse matrix to a dense matrix\n",
    "train_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aafp</th>\n",
       "      <th>aafp feline</th>\n",
       "      <th>aardwolf</th>\n",
       "      <th>aardwolf cristatus</th>\n",
       "      <th>aaroki</th>\n",
       "      <th>aaroki votes</th>\n",
       "      <th>abalone</th>\n",
       "      <th>abalone centre</th>\n",
       "      <th>abalone console</th>\n",
       "      <th>abalones</th>\n",
       "      <th>...</th>\n",
       "      <th>zoonosis cats</th>\n",
       "      <th>zoonosis registries</th>\n",
       "      <th>zoonotic</th>\n",
       "      <th>zoonotic canadian</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zorro remaining</th>\n",
       "      <th>zs</th>\n",
       "      <th>zs vincze</th>\n",
       "      <th>zsq</th>\n",
       "      <th>zsq days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aafp  aafp feline  aardwolf  aardwolf cristatus  aaroki  aaroki votes  \\\n",
       "0     0            0         0                   0       0             0   \n",
       "1     0            0         0                   0       0             0   \n",
       "2     0            0         0                   0       0             0   \n",
       "3     0            0         0                   0       0             0   \n",
       "4     0            0         0                   0       0             0   \n",
       "\n",
       "   abalone  abalone centre  abalone console  abalones    ...     \\\n",
       "0        0               0                0         0    ...      \n",
       "1        0               0                0         0    ...      \n",
       "2        0               0                0         0    ...      \n",
       "3        0               0                0         0    ...      \n",
       "4        0               0                0         0    ...      \n",
       "\n",
       "   zoonosis cats  zoonosis registries  zoonotic  zoonotic canadian  zorro  \\\n",
       "0              0                    0         0                  0      0   \n",
       "1              0                    0         0                  0      0   \n",
       "2              0                    0         0                  0      0   \n",
       "3              0                    0         0                  0      0   \n",
       "4              0                    0         0                  0      0   \n",
       "\n",
       "   zorro remaining  zs  zs vincze  zsq  zsq days  \n",
       "0                0   0          0    0         0  \n",
       "1                0   0          0    0         0  \n",
       "2                0   0          0    0         0  \n",
       "3                0   0          0    0         0  \n",
       "4                0   0          0    0         0  \n",
       "\n",
       "[5 rows x 32160 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the vocabulary and document-term matrix together\n",
    "doc_term_df= pd.DataFrame(train_dtm.toarray(), columns=count_vectorizer.get_feature_names())\n",
    "doc_term_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test data X_test. Create test document term matrix: test_dtm \n",
    "# Use ONLY the .transform() method, NOT fit method\n",
    "test_dtm = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aafp', 'aafp feline', 'aardwolf', 'aardwolf cristatus', 'aaroki', 'aaroki votes', 'abalone', 'abalone centre', 'abalone console', 'abalones', 'abalones abalone', 'abalones dominators', 'abandonment', 'abandonment household', 'abap', 'abap asked', 'abarth', 'abarth alfa', 'abarth spider', 'abbreviated', 'abbreviated make', 'abby', 'abby ellin', 'abc', 'abc look', 'abc news', 'abcarian', 'abcarian h', 'abe', 'abe parent', 'aberration', 'aberration needed', 'abigail', 'abigail lion', 'ability', 'ability cat', 'ability cats', 'ability characteristic', 'ability create', 'ability digest', 'ability distinguish', 'ability glands', 'ability hunt', 'ability synthesize', 'ability taste', 'ability thrive', 'ability undergo', 'able', 'able authenticate', 'able devote', 'able generally', 'able tolerate', 'abnormalities', 'abnormalities accompanied', 'abril', 'abril archived', 'absence', 'absence mainland', 'absinth', 'absinth items', 'absinth ritifs', 'absolute', 'absolute excellence', 'absolute math', 'absolutely', 'absolutely forbidden', 'absolutely unlimited', 'absorption', 'absorption calcium', 'abstracts', 'abstracts reviewed', 'abu', 'abu hurairah', 'abu hurayrah', 'abuelo', 'abuelo year', 'abundance', 'abundance smaller', 'abundance sources', 'abuse', 'abuse does', 'abuse power', 'abuse report', 'abusing', 'abusing stepdaughter', 'abusive', 'abusive action', 'abyssinian', 'abyssinian american', 'abyssinian genet', 'abyssinica', 'abyssinica angolan', 'aca', 'aca parent', 'academia', 'academia entrepreneur', 'academia law', 'academies', 'academies isbn', 'academies science', 'academy', 'academy archived', 'academy award', 'academy container', 'academy help', 'academy sciences', 'accelerate', 'accelerate progress', 'accelerating', 'accelerating aids', 'accelerating decline', 'accelerator', 'accelerator just', 'accelerators', 'accelerators allow', 'accelerators launchpad', 'accent', 'accent adding', 'accent black', 'accent color', 'acceptability', 'acceptability feasibility', 'access', 'access amazing', 'access care', 'access catalogue', 'access community', 'access contact', 'access effective', 'access entire', 'access file', 'access food', 'access medicines', 'access nacc', 'access normal', 'access pharmaceuticals', 'access processes', 'access timestamp', 'accessed', 'accessed august', 'accessibility', 'accessibility cookie', 'accessibility statement', 'accessing', 'accessing aids', 'accident', 'accident clementi', 'accident james', 'accompanied', 'accompanied developmental', 'accompanied muscle', 'accomplish', 'accomplish main', 'accordance', 'accordance s', 'according', 'according dominance', 'according italian', 'according myth', 'according norman', 'according stats', 'according technical', 'according times', 'account', 'account centralized', 'account checkout', 'account clock', 'account executive', 'account log', 'account management', 'account request', 'account s', 'accountability', 'accountability heart', 'accountability hiv', 'accountable', 'accountable estimated', 'accredited', 'accredited training', 'accrued', 'accrued various', 'accueil', 'accueil du', 'accuracy', 'accuracy analog', 'accuracy relevant', 'accuracy susie', 'accurately', 'accurately site', 'accused', 'accused fighting', 'accused involvement', 'accused read', 'acenta', 'acenta dr', 'acetyl', 'acetyl coenzyme', 'achap', 'achap botswana', 'achap currently', 'achap head', 'achap hybrid', 'achap latest', 'achap links', 'achap management', 'achap nanaso', 'achap provided', 'achap selected', 'achap successfully', 'acharya', 'acharya vote', 'achieve', 'achieve online', 'achieve s', 'acid', 'acid activity', 'acid alternate', 'acid american', 'acid arachidonic', 'acid arginine', 'acid cats', 'acid containing', 'acid converts', 'acid cysteine', 'acid decarboxylase', 'acid docosahexaenoic', 'acid essential', 'acid journal', 'acid mammals', 'acid metabolized', 'acid mononlucleotide', 'acid omega', 'acid requirements', 'acid used', 'acid usual', 'acids', 'acids continue', 'acids despite', 'acids eicosapentaenoic', 'acinonyx', 'acinonyx atypical', 'acinonyx cheetah', 'acknowledgements', 'acknowledgements generous', 'acknowledgements media', 'acne', 'acne asthma', 'acquire', 'acquire infections', 'acrobat', 'acrobat reader', 'act', 'act activists', 'act came', 'act cap', 'act like', 'act occurs', 'act received', 'act registration', 'acta', 'acta anatomica', 'actinidia', 'actinidia polygama', 'action', 'action challenges', 'action email', 'action google', 'action group', 'action lost', 'action msm', 'action msmt', 'action national', 'action output', 'action plan', 'action programmes', 'action provides', 'action special', 'action teams', 'actions', 'actions escalate', 'active', 'active community', 'active day', 'active img', 'active look', 'active males', 'active morning', 'active national', 'active thumbnail', 'active timing', 'actively', 'actively engaged', 'actively stalk', 'activer', 'activer javascript', 'activist', 'activist james', 'activists', 'activists african', 'activists civil', 'activists skills', 'activists transforming', 'activists welcome', 'activities', 'activities advocacy', 'activities african', 'activities friday', 'activities population', 'activities september', 'activities southern', 'activities stakeholders', 'activity', 'activity cystinesulfinic', 'activity domestic', 'activity means', 'activity process', 'activity quite', 'activity spend', 'activity use', 'actress', 'actress messenger', 'acts', 'acts friendly', 'acts induce', 'actually', 'actually attracts', 'actually useful', 'acufarl', 'acufarl day', 'acufarl evrfydivhv', 'acufarl rx', 'acute', 'acute chronic', 'acute range', 'acute sense', 'acuxbit', 'acuxbit s', 'ad', 'ad agencies', 'ad april', 'ad martial', 'adam', 'adam pet', 'adaptable', 'adaptable present', 'adaptation', 'adaptation cats', 'adaptation dim', 'adaptation domestication', 'adaptation low', 'adaptation preferred', 'adaptations', 'adaptations allow', 'adaptations s', 'adapted', 'adapted cat', 'adapted hunting', 'adapted killing', 'adapted meat', 'adapting', 'adapting predictive', 'adaptive', 'adaptive driven', 'adaptive radiation', 'add', 'add bright', 'add browsable', 'add cobalt', 'add layers', 'add little', 'add media', 'add red', 'add remove', 'add warmth', 'added', 'added cart', 'added national', 'adding', 'adding brighter', 'adding cart', 'adding input', 'addition', 'addition light', 'addition lower', 'additional', 'additional rehydrate', 'additional terms', 'additions', 'additions site', 'additive', 'additive cat', 'address', 'address achap', 'address consent', 'address economic', 'address issues', 'address key', 'address ll', 'address password', 'address private', 'address protected', 'address ready', 'address spy', 'addresses', 'addresses contact', 'addresses host', 'addressing', 'addressing human', 'addressing structural', 'adds', 'adds burst', 'adds cheerfulness', 'adds new', 'ade', 'ade celebrity', 'adequacy', 'adequacy vegan', 'adequate', 'adequate quantities', 'adherence', 'adherence adherence', 'adherence advocacy', 'adherence past', 'admin', 'admin news', 'admin previous', 'adminhtml', 'adminhtml asked', 'adminhtml page', 'administered', 'administered general', 'administration', 'administration ignores', 'administration ignoring', 'administration webmail', 'administrative', 'administrative relief', 'administrators', 'administrators drupal', 'adobe', 'adobe acrobat', 'adolescence', 'adolescence sexual', 'adolescent', 'adolescent aids', 'adolescent fast', 'adolescent girls', 'adolescent pamphlets', 'adolescent responsive', 'adolescent voluntary', 'adolescents', 'adolescents aids', 'adolescents hiv', 'adolescents young', 'adolescents youth', 'adopt', 'adopt humans', 'adopted', 'adopted friday', 'adopting', 'adopting s', 'adoption', 'adoption program', 'adopts', 'adopts tougher', 'adrien', 'adrien s', 'ads', 'ads build', 'ads enterprise', 'ads log', 'ads marketplace', 'adult', 'adult cat', 'adult cats', 'adult domestic', 'adult housecats', 'adult male', 'adult pademelon', 'adustus', 'adustus african', 'advance', 'advance civil', 'advance human', 'advance social', 'advanced', 'advanced audience', 'advanced clinical', 'advanced control', 'advanced programming', 'advances', 'advances farm', 'advancing', 'advancing hiv', 'advancing science', 'advantage', 'advantage scale', 'advantage signalling', 'advantages', 'advantages running', 'advent', 'advent recent', 'adverse', 'adverse event', 'advertise', 'advertise advertise', 'advertise contact', 'advertise container', 'advertise insights', 'advertise legal', 'advertise subscribe', 'advertisement', 'advertisement advertisement', 'advertisement asian', 'advertisement california', 'advertisement channel', 'advertisement festival', 'advertisement inside', 'advertisement mainstream', 'advertisement mediacorp', 'advertisement nation', 'advertisement px', 'advertisement sign', 'advertisement singapore', 'advertisement social', 'advertisement try', 'advertisement videos', 'advertisement wants', 'advertising', 'advertising academy', 'advertising copyright', 'advertising effective', 'advertising materials', 'advertising news', 'advertising online', 'advertising products', 'advertising tv', 'advice', 'advice bipartisan', 'advice home', 'advice pharmaceutical', 'advice preventing', 'advice service', 'advisor', 'advisor united', 'advisor va', 'advisory', 'advisory board', 'advisory panel', 'advocacy', 'advocacy efforts', 'advocacy human', 'advocacy increased', 'advocacy initiative', 'advocacy initiatives', 'advocacy international', 'advocacy national', 'advocacy news', 'advocacy regional', 'advocacy reports', 'advocates', 'advocates opposing', 'advocates report', 'advocates using', 'aegean', 'aegean cyprus', 'aesthetic', 'aesthetic seen', 'affairs', 'affairs pets', 'affect', 'affect including', 'affected', 'affected learn', 'affected people', 'affected response', 'affecting', 'affecting join', 'affecting pica', 'affection', 'affection humans', 'affection superstitions', 'affiliate', 'affiliate network', 'affiliate program', 'affiliated', 'affiliated endorsed', 'affiliates', 'affiliates careers', 'affiliates connect', 'affiliates resellers', 'affiliates sm', 'afghanistan', 'afghanistan aland', 'afghanistan pakistan', 'aficionado', 'aficionado association', 'afq', 'afq afq', 'afq hours', 'africa', 'africa achap', 'africa applaud', 'africa asia', 'africa cat', 'africa centers', 'africa contact', 'africa converges', 'africa december', 'africa development', 'africa hiv', 'africa litigation', 'africa programme', 'africa read', 'africa receives', 'africa regional', 'africa retain', 'africa south', 'africa suisse', 'africa swaziland', 'africa x', 'african', 'african american', 'african civet', 'african civil', 'african clawless', 'african countries', 'african day', 'african golden', 'african headquartered', 'african linsang', 'african palm', 'african republic', 'african sector', 'african striped', 'african union', 'african variety', 'african wild', 'african wildcat', 'africana', 'africana mountain', 'africats', 'africats dna', 'afrikaans', 'afrikaans alemannisch', 'afternoon', 'afternoon dark', 'afternoon lunch', 'age', 'age discovery', 'age gonadectomy', 'age immune', 'age neutering', 'age return', 'age spaying', 'age weeks', 'aged', 'aged new', 'aged year', 'aged years', 'agencies', 'agencies consultancies', 'agencies reach', 'agency', 'agency climate', 'agency international', 'agency program', 'agenda', 'agenda identified', 'agenda kenya', 'agenda maisha', 'agent', 'agent modified', 'agent read', 'agents', 'agents intelligence', 'agentspeak', 'agentspeak trying', 'ages', 'ages s', 'aggravating', 'aggravating boost', 'aggression', 'aggression domestic', 'aggression family', 'aggression households', 'aggressiveness', 'aggressiveness newly', 'aging', 'aging cats', 'aging declawing', 'agnihotri', 'agnihotri votes', 'ago', 'ago aaroki', 'ago afq', 'ago ajay', 'ago ajwerth', 'ago alasdair', 'ago aleksey', 'ago alexander', 'ago alexandre', 'ago alexey', 'ago alfran', 'ago andreas', 'ago andrey', 'ago android', 'ago anh', 'ago animal', 'ago anothernode', 'ago anu', 'ago anuradha', 'ago arsenii', 'ago ashish', 'ago bacon', 'ago baglin', 'ago banky', 'ago bharath', 'ago bigdave', 'ago buddha', 'ago calculon', 'ago china', 'ago chinni', 'ago coder', 'ago condoms', 'ago crcalin', 'ago crotaphytus', 'ago csl', 'ago cucuru', 'ago damienzonly', 'ago dangonfast', 'ago darkhan', 'ago dave', 'ago david', 'ago deazzle', 'ago denisemeander', 'ago details', 'ago dineshdb', 'ago don', 'ago donnovan', 'ago duane', 'ago efforts', 'ago enanone', 'ago ere', 'ago eshfaq', 'ago eugenio', 'ago frontend', 'ago gabriele', 'ago genetic', 'ago george', 'ago glopes', 'ago gordon', 'ago hemakumar', 'ago ighour', 'ago imylor', 'ago include', 'ago itaybz', 'ago jaimerr', 'ago jamone', 'ago javaintern', 'ago jay', 'ago jayaram', 'ago jesse', 'ago jjayadeep', 'ago john', 'ago jpp', 'ago jsalvata', 'ago jvoelker', 'ago k', 'ago kahoona', 'ago kaounkaoun', 'ago karan', 'ago kenya', 'ago kerem', 'ago ketajw', 'ago kvolden', 'ago kzrystof', 'ago laurie', 'ago legatux', 'ago lena', 'ago limon', 'ago lokesh', 'ago looking', 'ago louis', 'ago ludo', 'ago m', 'ago maddy', 'ago majthehero', 'ago manon', 'ago matthew', 'ago matthijs', 'ago max', 'ago mi', 'ago michael', 'ago michal', 'ago mihkel', 'ago mjgalindo', 'ago moe', 'ago mohd', 'ago moooeeeep', 'ago muhmarigo', 'ago nal', 'ago naveen', 'ago near', 'ago newbie', 'ago nicolas', 'ago nihal', 'ago nocturne', 'ago o', 'ago ofek', 'ago oliver', 'ago osman', 'ago pammu', 'ago paolo', 'ago pavel', 'ago phdstudent', 'ago pierre', 'ago prajwal', 'ago prateek', 'ago qharr', 'ago rajdeep', 'ago ramesh', 'ago rasiya', 'ago rdon', 'ago red', 'ago resources', 'ago revo', 'ago roberto', 'ago rt', 'ago rudresh', 'ago russ', 'ago rwallace', 'ago s', 'ago sachin', 'ago sam', 'ago schreiber', 'ago seff', 'ago sharpshade', 'ago shree', 'ago shweta', 'ago shyamal', 'ago silouane', 'ago simas', 'ago simran', 'ago skadoosh', 'ago stephen', 'ago tapaka', 'ago tdc', 'ago tender', 'ago thefolenangel', 'ago tobe', 'ago tomasz', 'ago trouselife', 'ago unai', 'ago unclebob', 'ago unor', 'ago v', 'ago vacancy', 'ago vaduha', 'ago varinder', 'ago varun', 'ago venkataraman', 'ago venkatesh', 'ago vidhuran', 'ago vifi', 'ago vincent', 'ago vineet', 'ago vladimir', 'ago vote', 'ago votes', 'ago web', 'ago william', 'ago yasir', 'ago yassine', 'ago yiguyigu', 'ago yinon', 'ago yunhao', 'ago z', 'ago zahid', 'ago zs', 'agrawal', 'agrawal h', 'agree', 'agree like', 'agree privacy', 'agree quantcast', 'agree terms', 'agreeing', 'agreeing use', 'agreement', 'agreement prevent', 'agriaid', 'agriaid sa', 'agriaidsa', 'agriaidsa agriaid', 'agricultural', 'agricultural alternatives', 'agricultural cats', 'agricultural fed', 'agricultural production', 'agricultural urban', 'agriculture', 'agriculture brought', 'agriculture committee', 'ahead', 'ahead southern', 'ahmad', 'ahmad votes', 'ahmed', 'ahmed centuries', 'ai', 'ai data', 'ai s', 'ai solutions', 'aid', 'aid community', 'aid honduras', 'aid navigation', 'aid popular', 'aid project', 'aids', 'aids activist', 'aids admin', 'aids africa', 'aids burden', 'aids click', 'aids commision', 'aids commission', 'aids competent', 'aids control', 'aids coordinator', 'aids created', 'aids deliver', 'aids effective', 'aids epidemic', 'aids founding', 'aids frequently', 'aids global', 'aids hiv', 'aids information', 'aids just', 'aids kenya', 'aids learn', 'aids m', 'aids maisha', 'aids mission', 'aids nacc', 'aids namibia', 'aids national', 'aids network', 'aids pepfar', 'aids policies', 'aids prevention', 'aids programmes', 'aids read', 'aids realize', 'aids regional', 'aids related', 'aids relief', 'aids report', 'aids research', 'aids response', 'aids results', 'aids rights', 'aids s', 'aids scientific', 'aids service', 'aids services', 'aids southern', 'aids staff', 'aids status', 'aids stop', 'aids strategic', 'aids strong', 'aids support', 'aids tb', 'aids test', 'aids today', 'aids trip', 'aids uganda', 'ailouros', 'ailouros meaning', 'ailuridae', 'ailuridae ailurus', 'ailurophobes', 'ailurophobes haters', 'ailurophobia', 'ailurophobia ailurophobia', 'ailurophobia assisted', 'ailurophobia cat', 'ailurophobia human', 'ailurophobia main', 'ailuropoda', 'ailuropoda giant', 'ailurus', 'ailurus red', 'aim', 'aim element', 'aim read', 'aimed']\n"
     ]
    }
   ],
   "source": [
    "# Print the first 1000 features of the count_vectorizer\n",
    "# using .get_feature_names() method\n",
    "print(count_vectorizer.get_feature_names()[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       1], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import MultinomialNB from sklearn.naive_bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Import the metrics module from sklearn \n",
    "from sklearn import metrics\n",
    "\n",
    "# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Fit the classifier to the training document term matrix\n",
    "nb_classifier.fit(train_dtm, y_train)\n",
    "\n",
    "# Compute the predicted tags for the test_data: pred\n",
    "pred = nb_classifier.predict(test_dtm)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9565217391304348\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy score for the classifier: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  1],\n",
       "       [ 0, 12]], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the confusion matrix\n",
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55    About Companies People YC Continuity Startup S...\n",
       "Name: text_dump, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the site contents for the false positives (Irrelevant sites incorrectly classified as HIV related)\n",
    "X_test[y_test < pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: text_dump, dtype: object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the site contents for the false negatives (HIV related sites incorrectly classified as Irrelevant)\n",
    "X_test[y_test > pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+000, 1.75320483e-006, 1.00000000e+000, 0.00000000e+000,\n",
       "       1.00000000e+000, 2.11489935e-116, 1.00000000e+000, 1.00000000e+000,\n",
       "       6.67592586e-032, 1.00000000e+000, 1.00000000e+000, 9.99898277e-001,\n",
       "       6.15826498e-007, 9.32855734e-015, 1.00000000e+000, 1.00000000e+000,\n",
       "       1.00000000e+000, 2.10318452e-073, 3.53416039e-173, 4.38788582e-009,\n",
       "       1.00000000e+000, 5.09687377e-045, 1.00000000e+000])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate predicted probabilities for X_test (poorly calibrated)\n",
    "y_pred_prob = nb_classifier.predict_proba(test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-10.81685401 -10.81685401 -10.81685401 ... -10.81685401 -10.12370683\n",
      "  -10.12370683]]\n"
     ]
    }
   ],
   "source": [
    "print(nb_classifier.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate a Pipline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='[A-Za-z]+(?=\\\\s+)',\n",
       "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create the token pattern in order to include only alpha characters: TOKENS_ALPHA_ONLY \n",
    "TOKENS_ALPHA_ONLY = '[A-Za-z]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate Pipeline object: pl\n",
    "# Add the 'CountVectorizer' step (with the name 'vec') to the correct position in the pipeline\n",
    "pl = Pipeline([\n",
    "               ('vec', CountVectorizer(stop_words='english', token_pattern=TOKENS_ALPHA_ONLY, ngram_range=(1, 2))),\n",
    "               ('clf', MultinomialNB())\n",
    "    ])\n",
    "\n",
    "# Fit the Pipeline to the training data\n",
    "pl.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
